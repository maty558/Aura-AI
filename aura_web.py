import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
import io
try:
    import PyPDF2
except Exception:
    PyPDF2 = None
try:
    import pytesseract
except Exception:
    pytesseract = None
import time
from google.api_core import exceptions as api_exceptions

# 1. NASTAVENIA A PAM√Ñ≈§
load_dotenv()
# fallback: najprv GOOGLE_API_KEY, potom API_KEY
api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("API_KEY")
if api_key:
    genai.configure(api_key=api_key)
else:
    st.error("Ch√Ωba API kƒæ√∫ƒç! Nastav GOOGLE_API_KEY alebo API_KEY v .env")

# Poradie modelov (fallback pri kv√≥tach / NotFound)
model_candidates = [
    "models/text-bison-001",           # text-focused model (commonly available)
    "models/gemini-2.5-pro",
    "models/gemini-2.5-flash",
    "models/gemini-flash-latest",
    "models/gemini-flash-lite",
]

st.set_page_config(page_title="Aura AI", page_icon="üõ°Ô∏è", layout="wide")

# Inicializ√°cia hist√≥rie (Session State)
if 'history' not in st.session_state:
    st.session_state['history'] = []

# --- BOƒåN√ù PANEL (PROFIL A HIST√ìRIA) ---
with st.sidebar:
    st.title("üë§ Profil pou≈æ√≠vateƒæa")
    # Tu s√∫ polia, ktor√© si chcel doplni≈•
    user_name = st.text_input("Meno", placeholder="Tvoje meno")
    user_email = st.text_input("E-mail", placeholder="priklad@mail.sk")
    user_age = st.number_input("Vek", min_value=0, max_value=120, value=25)
    
    st.divider()
    st.subheader("üìú Moja hist√≥ria")
    if st.session_state['history']:
        for i, item in enumerate(reversed(st.session_state['history'])):
            st.write(f"{len(st.session_state['history'])-i}. {item}")
        
        if st.button("Vymaza≈• v≈°etko"):
            st.session_state['history'] = []
            st.rerun()
    else:
        st.info("Zatiaƒæ ≈æiadna aktivita.")

# --- HLAVN√Å ƒåAS≈§ APLIK√ÅCIE ---
st.title(f"üõ°Ô∏è Aura")
if 'user_name' in locals() and user_name:
    st.write(f"Vitaj, **{user_name}**. Som pripraven√° ≈•a chr√°ni≈•.")
else:
    st.write("Som tvoj inteligentn√Ω ochran√°r. Povedz mi, ƒço sa deje.")

# SEKCIA: UK√Å≈Ω MI (FOTO aj PDF)
st.header("üëÅÔ∏è Re≈æim: Uk√°≈æ mi")

# 1. Tu sme pridali 'pdf' do zoznamu povolen√Ωch form√°tov
upload = st.file_uploader("Odfo≈• alebo nahraj dokument (JPG, PNG, PDF)", type=['jpg', 'png', 'jpeg', 'pdf'])

if upload:
    # Kontrola, ƒçi ide o PDF alebo obr√°zok pre zobrazenie n√°hƒæadu
    if upload.type == "application/pdf":
        st.write("üìÑ S√∫bor PDF bol √∫spe≈°ne nahran√Ω.")
    else:
        img = Image.open(upload)
        st.image(img, caption="N√°hƒæad dokumentu", width=400)
    
    if st.button("Analyzuj dokument"):
        with st.spinner("Aura ƒç√≠ta dokument (m√¥≈æe to trva≈• chv√≠ƒæu)..."):
            prompt = "Si Aura, ochran√°rsky asistent. Analyzuj tento dokument. ƒåo to je? N√°jdi üö© RIZIKO, ‚úÖ FAKT a üöÄ AKCIA."

            # Pok√∫sime sa najprv extrahova≈• text lok√°lne (PDF alebo OCR z obr√°zka)
            extracted_text = None
            if upload.type == "application/pdf":
                pdf_data = upload.read()
                if PyPDF2 is not None:
                    try:
                        reader = PyPDF2.PdfReader(io.BytesIO(pdf_data))
                        pages = [p.extract_text() or "" for p in reader.pages]
                        extracted_text = "\n".join(pages).strip()
                    except Exception:
                        extracted_text = None
                else:
                    extracted_text = None
            else:
                # obr√°zok
                img_obj = Image.open(upload)
                if pytesseract is not None:
                    try:
                        extracted_text = pytesseract.image_to_string(img_obj).strip()
                    except Exception:
                        extracted_text = None

            response = None
            last_exc = None
            for idx, candidate in enumerate(model_candidates):
                try:
                    model = genai.GenerativeModel(candidate)
                    # prefer text model when we have extracted text
                    if candidate.startswith("models/text"):
                        if extracted_text:
                            combined = f"{prompt}\n\nExtrahovan√Ω text:\n{extracted_text}"
                            response = model.generate_content(combined)
                            break
                        else:
                            continue
                    else:
                        # multimod√°lne modely: posla≈• p√¥vodn√© d√°ta
                        if upload.type == "application/pdf":
                            response = model.generate_content([
                                prompt,
                                {'mime_type': 'application/pdf', 'data': pdf_data}
                            ])
                        else:
                            response = model.generate_content([prompt, img_obj])
                        break
                except api_exceptions.ResourceExhausted as rex:
                    last_exc = rex
                    backoff = min(2 ** idx, 8)
                    time.sleep(backoff)
                    continue
                except api_exceptions.NotFound as nf:
                    last_exc = nf
                    continue
                except Exception as e:
                    last_exc = e
                    continue

            if response is None:
                if isinstance(last_exc, api_exceptions.ResourceExhausted):
                    st.error("Kv√≥ta vyƒçerpan√° pre pou≈æit√© modely. Skontroluj faktur√°ciu / kv√≥ty.")
                elif isinstance(last_exc, api_exceptions.NotFound):
                    st.error("Po≈æadovan√© modely nie s√∫ dostupn√© pre tvoje API/verziu.")
                else:
                    st.error(f"Chyba pri volan√≠ modelu: {last_exc}")
            else:
                st.session_state['history'].append(f"Dokument: {response.text[:40]}...")
                st.subheader("V√Ωsledok anal√Ωzy:")
                st.write(response.text)

st.divider()

# SEKCIA: POM√î≈Ω MI (TEXT)
st.header("üí¨ Re≈æim: Pom√¥≈æ mi")
problem = st.text_area("Pop√≠≈° svoju situ√°ciu:")

if st.button("Vyrie≈° to"):
    if problem:
        with st.spinner("Hƒæad√°m rie≈°enie..."):
            response = None
            last_exc = None
            for idx, candidate in enumerate(model_candidates):
                try:
                    model = genai.GenerativeModel(candidate)
                    response = model.generate_content(f"Si Aura, ochran√°r. Vyrie≈° toto: {problem}")
                    break
                except api_exceptions.ResourceExhausted as rex:
                    last_exc = rex
                    backoff = min(2 ** idx, 8)
                    time.sleep(backoff)
                    continue
                except api_exceptions.NotFound as nf:
                    last_exc = nf
                    continue
                except Exception as e:
                    last_exc = e
                    continue

            if response is None:
                if isinstance(last_exc, api_exceptions.ResourceExhausted):
                    st.error("Kv√≥ta vyƒçerpan√° pre pou≈æit√© modely. Skontroluj faktur√°ciu / kv√≥ty.")
                elif isinstance(last_exc, api_exceptions.NotFound):
                    st.error("Po≈æadovan√© modely nie s√∫ dostupn√© pre tvoje API/verziu.")
                else:
                    st.error(f"Chyba pri volan√≠ modelu: {last_exc}")
            else:
                st.session_state['history'].append(f"Text: {problem[:40]}...")
                st.write(response.text)