"""Streamlit UI pre Aura: nahrÃ¡vanie a analÃ½za dokumentov a textovÃ© poradenstvo.

Obsahuje dve hlavnÃ© sekcie: nahratie dokumentu (analÃ½za) a textovÃ© otÃ¡zky
(poradenstvo). AplikÃ¡cia komunikuje s generatÃ­vnym API (Gemini).
"""

# pylint: disable=trailing-newlines

import os
from typing import Any, List

from dotenv import load_dotenv
import streamlit as st
import google.generativeai as genai
from PIL import Image

# 1. NASTAVENIA API A KONFIGURÃCIA
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

if not API_KEY:
    st.error("âŒ ChÃ½ba API kÄ¾ÃºÄ v sÃºbore .env! ProsÃ­m, pridaj ho.")
    st.stop()

genai.configure(api_key=API_KEY)

# KonfigurÃ¡cia Streamlit strÃ¡nky
st.set_page_config(
    page_title="Aura AI - OchranÃ¡r",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
)


def get_best_model() -> str:
    """ZÃ­skaÅ¥ najvhodnejÅ¡Ã­ model z dostupnÃ½ch alebo vrÃ¡tiÅ¥ zÃ¡loÅ¾nÃ½.

    Preferuje modely obsahujÃºce 'flash', inak prvÃ½ dostupnÃ½.
    """
    try:
        available_models: List[str] = []
        for m in genai.list_models():
            if hasattr(m, "supported_generation_methods"):
                if "generateContent" in m.supported_generation_methods:
                    if hasattr(m, "name"):
                        available_models.append(m.name)

        chosen = next((m for m in available_models if "flash" in m), None)
        if not chosen:
            chosen = available_models[0] if available_models else "models/gemini-1.5-flash"
        return chosen
    except Exception:  # pylint: disable=broad-except
        return "models/gemini-1.5-flash"


# InicializÃ¡cia histÃ³rie analÃ½z (st.session_state zostÃ¡va v pamÃ¤ti poÄas relÃ¡cie)
if "history" not in st.session_state:
    st.session_state["history"] = []


# --- BOÄŒNÃ PANEL (Sidebar) ---
with st.sidebar:
    st.title("ğŸ‘¤ Profil pouÅ¾Ã­vateÄ¾a")
    u_name = st.text_input("Meno", value="PouÅ¾Ã­vateÄ¾")
    u_email = st.text_input("E-mail", placeholder="tvoj@email.sk")

    st.divider()
    st.subheader("ğŸ“œ HistÃ³ria aktivÃ­t")

    if st.session_state["history"]:
        for entry in reversed(st.session_state["history"]):
            st.info(entry)

        if st.button("ğŸ—‘ï¸ VymazaÅ¥ histÃ³riu"):
            st.session_state["history"] = []
            st.rerun()
    else:
        st.write("ZatiaÄ¾ Å¾iadna histÃ³ria.")


# --- HLAVNÃ ÄŒASÅ¤ APLIKÃCIE ---
st.title("ğŸ›¡ï¸ Aura AI")
st.markdown(
    f"**Ahoj {u_name}, som tvoj digitÃ¡lny ochranÃ¡r.** "
    "PomÃ´Å¾em ti preveriÅ¥ dokumenty alebo poradiÅ¥ s prÃ¡vami spotrebiteÄ¾a."
)


# 1. SEKCIA: UKÃÅ½ MI (Skenovanie a nahrÃ¡vanie)
with st.expander("ğŸ‘ï¸ ReÅ¾im: UkÃ¡Å¾ mi (AnalÃ½za dokumentu)", expanded=True):
    st.write("Nahraj fotografiu zmluvy, bloÄku alebo PDF sÃºbor.")
    uploaded_file = st.file_uploader(
        "Vyber sÃºbor (JPG, PNG, PDF)", type=["jpg", "jpeg", "png", "pdf"]
    )

    if uploaded_file:
        # Zobrazenie nÃ¡hÄ¾adu, ak ide o obrÃ¡zok
        if uploaded_file.type != "application/pdf":
            img_preview = Image.open(uploaded_file)
            st.image(img_preview, caption="NÃ¡hÄ¾ad dokumentu", width=300)
        else:
            st.write("ğŸ“„ Dokument PDF je pripravenÃ½ na analÃ½zu.")

        if st.button("ğŸš€ SpustiÅ¥ analÃ½zu"):
            with st.spinner("Aura dÃ´kladne analyzuje obsah dokumentu..."):
                try:
                    # DynamickÃ© zÃ­skanie modelu
                    model_name = get_best_model()
                    model = genai.GenerativeModel(model_name)

                    # DefinÃ­cia inÅ¡trukciÃ­ pre AI
                    ANALYSIS_PROMPT = (
                        "Si Aura, expert na ochranu spotrebiteÄ¾a a digitÃ¡lnu bezpeÄnosÅ¥. "
                        "Analyzuj tento dokument a Å¡truktÃºruj odpoveÄ takto:\n"
                        "1. ÄŒo je to za dokument?\n"
                        "2. ğŸš© RIZIKÃ (ak nejakÃ© existujÃº)\n"
                        "3. âœ… KÄ½ÃšÄŒOVÃ‰ FAKTY (termÃ­ny, sumy, podmienky)\n"
                        "4. ğŸš€ ODPORÃšÄŒANÃ AKCIA (Äo mÃ¡ pouÅ¾Ã­vateÄ¾ urobiÅ¥).\n"
                        "Odpovedaj v slovenÄine, buÄ struÄnÃ½ a jasnÃ½."
                    )

                    content_to_send: List[Any] = [ANALYSIS_PROMPT]

                    # Spracovanie podÄ¾a typu sÃºboru
                    if uploaded_file.type == "application/pdf":
                        pdf_bytes = uploaded_file.read()
                        content_to_send.append(
                            {"mime_type": "application/pdf", "data": pdf_bytes}
                        )
                    else:
                        img_data = Image.open(uploaded_file)
                        content_to_send.append(img_data)

                    # Odoslanie do Gemini
                    response = model.generate_content(content_to_send)

                    # Zobrazenie vÃ½sledku
                    st.markdown("---")
                    st.subheader("ğŸ“Š VÃ½sledok od Aury")
                    st.markdown(response.text)

                    # UloÅ¾enie do histÃ³rie
                    st.session_state["history"].append(
                        f"AnalyzovanÃ©: {uploaded_file.name}"
                    )
                except Exception as e:  # pylint: disable=broad-except
                    st.error(f"Nastala chyba pri komunikÃ¡cii s AI: {e}")


# 2. SEKCIA: POMÃ”Å½ MI (TextovÃ© otÃ¡zky)
with st.expander("ğŸ’¬ ReÅ¾im: PomÃ´Å¾ mi (PrÃ¡vna rada)"):
    st.write(
        "PopÃ­Å¡ svoj problÃ©m (napr. 'Chcem vrÃ¡tiÅ¥ tovar zakÃºpenÃ½ v e-shope pred 10 dÅˆami')."
    )
    user_problem = st.text_area("Tvoj problÃ©m alebo otÃ¡zka:")

    if st.button("ğŸ’¡ ZÃ­skaÅ¥ odporÃºÄanie"):
        if user_problem:
            with st.spinner("HÄ¾adÃ¡m najlepÅ¡ie rieÅ¡enie pre teba..."):
                try:
                    model_name = get_best_model()
                    model = genai.GenerativeModel(model_name)

                    ADVICE_PROMPT = (
                        f"Si Aura, expert na ochranu spotrebiteÄ¾a. Navrhni najlepÅ¡Ã­ prÃ¡vny "
                        f"a praktickÃ½ postup pre tÃºto situÃ¡ciu: {user_problem}. "
                        "Odpovedaj v bodoch v slovenÄine."
                    )

                    response = model.generate_content(ADVICE_PROMPT)

                    st.markdown("---")
                    st.subheader("ğŸ’¡ OdporÃºÄanie Aury")
                    st.markdown(response.text)

                    # UloÅ¾enie do histÃ³rie
                    st.session_state["history"].append(f"OtÃ¡zka: {user_problem[:30]}...")
                except Exception as e:  # pylint: disable=broad-except
                    st.error(f"Chyba: {e}")

        else:
            st.warning("ProsÃ­m, napÃ­Å¡ najprv svoj problÃ©m.")



